{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "import statsmodels.api   as sm\n",
    "import scipy.stats       as stats\n",
    "import lightgbm          as lgb\n",
    "import datetime          as dt\n",
    "import matplotlib\n",
    "import pydotplus\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from math                      import sqrt\n",
    "\n",
    "from sklearn.datasets          import load_boston\n",
    "from sklearn.model_selection   import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model      import LinearRegression, LogisticRegression\n",
    "from sklearn.linear_model      import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.linear_model      import ElasticNetCV, ElasticNet\n",
    "from sklearn.metrics           import mean_squared_error\n",
    "from sklearn.metrics           import r2_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics           import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.tree              import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.externals.six     import StringIO\n",
    "from sklearn.preprocessing     import StandardScaler\n",
    "from sklearn.ensemble          import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors         import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.naive_bayes       import BernoulliNB\n",
    "from sklearn.svm               import SVC, SVR\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster           import KMeans, AgglomerativeClustering\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from collections               import Counter as count\n",
    "\n",
    "from IPython.display           import Image\n",
    "\n",
    "from scipy.stats               import randint as sp_randint\n",
    "from scipy.cluster.hierarchy   import dendrogram, linkage\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from imblearn.over_sampling    import SMOTE\n",
    "\n",
    "from category_encoders         import TargetEncoder\n",
    "\n",
    "from scipy.stats               import ttest_1samp,ttest_ind, wilcoxon\n",
    "\n",
    "from statsmodels.stats.power   import ttest_power\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>DEFAULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  DEFAULT  \n",
       "0         0         0         0        1  \n",
       "1      1000         0      2000        1  \n",
       "2      1000      1000      5000        0  \n",
       "3      1100      1069      1000        0  \n",
       "4      9000       689       679        0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('credit_card.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      "ID           30000 non-null int64\n",
      "LIMIT_BAL    30000 non-null int64\n",
      "SEX          30000 non-null int64\n",
      "EDUCATION    30000 non-null int64\n",
      "MARRIAGE     30000 non-null int64\n",
      "AGE          30000 non-null int64\n",
      "PAY_1        30000 non-null int64\n",
      "PAY_2        30000 non-null int64\n",
      "PAY_3        30000 non-null int64\n",
      "PAY_4        30000 non-null int64\n",
      "PAY_5        30000 non-null int64\n",
      "PAY_6        30000 non-null int64\n",
      "BILL_AMT1    30000 non-null int64\n",
      "BILL_AMT2    30000 non-null int64\n",
      "BILL_AMT3    30000 non-null int64\n",
      "BILL_AMT4    30000 non-null int64\n",
      "BILL_AMT5    30000 non-null int64\n",
      "BILL_AMT6    30000 non-null int64\n",
      "PAY_AMT1     30000 non-null int64\n",
      "PAY_AMT2     30000 non-null int64\n",
      "PAY_AMT3     30000 non-null int64\n",
      "PAY_AMT4     30000 non-null int64\n",
      "PAY_AMT5     30000 non-null int64\n",
      "PAY_AMT6     30000 non-null int64\n",
      "DEFAULT      30000 non-null int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df.drop('DEFAULT',axis=1)\n",
    "y = df['DEFAULT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = logreg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion matrix - Train:  \n",
      " [[16363     1]\n",
      " [ 4635     1]]\n",
      "Overall accuracy - Train:  0.7792380952380953\n",
      "Confussion matrix - Test:  \n",
      " [[7000    0]\n",
      " [2000    0]]\n",
      "Overall accuracy - Test:  0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "print('Confussion matrix - Train: ','\\n',confusion_matrix(y_train,y_pred_train))\n",
    "print('Overall accuracy - Train: ',accuracy_score(y_train,y_pred_train))\n",
    "print('Confussion matrix - Test: ','\\n',confusion_matrix(y_test,y_pred))\n",
    "print('Overall accuracy - Test: ',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88      7000\n",
      "          1       0.00      0.00      0.00      2000\n",
      "\n",
      "avg / total       0.60      0.78      0.68      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88     16364\n",
      "          1       0.50      0.00      0.00      4636\n",
      "\n",
      "avg / total       0.72      0.78      0.68     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest_train:  0.9817619047619047\n",
      "Accuracy of Random Forest_test:  0.805\n",
      "AUC of Random Forest_train:  0.9993014361688328\n",
      "AUC of Random Forest_test:  0.7379866071428571\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10,random_state=1)\n",
    "\n",
    "rfc.fit(x_train,y_train)\n",
    "\n",
    "y_pred_train = rfc.predict(x_train)\n",
    "y_prob_train = rfc.predict_proba(x_train)[:,1]\n",
    "\n",
    "y_pred = rfc.predict(x_test)\n",
    "y_prob = rfc.predict_proba(x_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "print('Accuracy of Random Forest_train: ', accuracy_score(y_pred_train, y_train))\n",
    "print('Accuracy of Random Forest_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of Random Forest_train: ', roc_auc_score(y_train, y_prob_train))\n",
    "print('AUC of Random Forest_test: ', roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.94      0.88      7000\n",
      "          1       0.62      0.32      0.42      2000\n",
      "\n",
      "avg / total       0.78      0.81      0.78      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99     16364\n",
      "          1       1.00      0.92      0.96      4636\n",
      "\n",
      "avg / total       0.98      0.98      0.98     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 2,\n",
       " 'max_features': 15,\n",
       " 'min_samples_leaf': 16,\n",
       " 'min_samples_split': 12,\n",
       " 'n_estimators': 13}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=1)\n",
    "\n",
    "params = {'n_estimators': sp_randint(5,30),\n",
    "          'criterion' : ['gini','entropy'],\n",
    "          'max_depth' : sp_randint(2,10),\n",
    "          'min_samples_split' : sp_randint(2,20),\n",
    "          'min_samples_leaf' : sp_randint(1,20),\n",
    "          'max_features' : sp_randint(2,18)}\n",
    "\n",
    "rand_search_rfc = RandomizedSearchCV(rfc, param_distributions=params, random_state=1, cv=3)\n",
    "\n",
    "rand_search_rfc.fit(X,y)\n",
    "\n",
    "rand_search_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest_train:  0.8204285714285714\n",
      "Accuracy of RandomForest_test:  0.8176666666666667\n",
      "AUC of RandomForest_train:  0.7350142830207264\n",
      "AUC of RandomForest_test:  0.7251073214285714\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(**rand_search_rfc.best_params_)\n",
    "\n",
    "rfc.fit(x_train,y_train)\n",
    "\n",
    "y_pred_train = rfc.predict(x_train)\n",
    "y_prob_train = rfc.predict_proba(x_train)[:,1]\n",
    "\n",
    "y_pred = rfc.predict(x_test)\n",
    "y_prob = rfc.predict_proba(x_test)[:,1]\n",
    "\n",
    "print('Accuracy of RandomForest_train: ', accuracy_score(y_pred_train, y_train))\n",
    "print('Accuracy of RandomForest_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of RandomForest_train: ', roc_auc_score(y_train, y_prob_train))\n",
    "print('AUC of RandomForest_test: ', roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion matrix - Train:  \n",
      " [[15683   681]\n",
      " [ 3090  1546]]\n",
      "Overall accuracy - Train:  0.8204285714285714\n",
      "Confussion matrix - Test:  \n",
      " [[6728  272]\n",
      " [1369  631]]\n",
      "Overall accuracy - Test:  0.8176666666666667\n"
     ]
    }
   ],
   "source": [
    "print('Confussion matrix - Train: ','\\n',confusion_matrix(y_train,y_pred_train))\n",
    "print('Overall accuracy - Train: ',accuracy_score(y_train,y_pred_train))\n",
    "print('Confussion matrix - Test: ','\\n',confusion_matrix(y_test,y_pred))\n",
    "print('Overall accuracy - Test: ',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.96      0.89      7000\n",
      "          1       0.70      0.32      0.43      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.79      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.89     16364\n",
      "          1       0.69      0.33      0.45      4636\n",
      "\n",
      "avg / total       0.80      0.82      0.80     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgbc = lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbc.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lgbc.predict(x_test)\n",
    "y_prob = lgbc.predict_proba(x_test)[:,1]\n",
    "\n",
    "y_pred_train = lgbc.predict(x_train)\n",
    "y_prob_train = lgbc.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train Set:  0.851\n",
      "Accuracy on Test Set:  0.8186666666666667\n",
      "AUC of Train Set:  0.886816544883031\n",
      "AUC of Test Set:  0.7777822857142856\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on Train Set: ', accuracy_score(y_train, y_pred_train))\n",
    "print('Accuracy on Test Set: ', accuracy_score(y_test, y_pred))\n",
    "print('AUC of Train Set: ', roc_auc_score(y_train, y_prob_train))\n",
    "print('AUC of Test Set: ', roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89      7000\n",
      "          1       0.67      0.35      0.47      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.80      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91     16364\n",
      "          1       0.79      0.44      0.57      4636\n",
      "\n",
      "avg / total       0.84      0.85      0.83     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM with Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_child_samples': 1, 'n_estimators': 65, 'num_leaves': 22}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "lgbc = lgb.LGBMClassifier(random_state=1)\n",
    "\n",
    "params = {'n_estimators': sp_randint(5,250),\n",
    "          'max_depth' : sp_randint(2,20),\n",
    "          'min_child_samples' : sp_randint(1,20),\n",
    "          'num_leaves' : sp_randint(5,50)}\n",
    "\n",
    "rand_search_lgbc = RandomizedSearchCV(lgbc, param_distributions=params, random_state=1, cv=3)\n",
    "\n",
    "rand_search_lgbc.fit(x_train, y_train)\n",
    "\n",
    "rand_search_lgbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LGBC_train:  0.8253333333333334\n",
      "Accuracy of LGBM_test:  0.8201111111111111\n",
      "AUC of LGBC_train:  0.8013530392690535\n",
      "AUC of LGBC_test:  0.7803508214285714\n"
     ]
    }
   ],
   "source": [
    "lgbc = lgb.LGBMClassifier(**rand_search_lgbc.best_params_, random_state=1)\n",
    "\n",
    "lgbc.fit(x_train,y_train)\n",
    "\n",
    "y_pred_train = lgbc.predict(x_train)\n",
    "y_prob_train = lgbc.predict_proba(x_train)[:,1]\n",
    "\n",
    "y_pred = lgbc.predict(x_test)\n",
    "y_prob = lgbc.predict_proba(x_test)[:,1]\n",
    "\n",
    "print('Accuracy of LGBC_train: ', accuracy_score(y_pred_train, y_train))\n",
    "print('Accuracy of LGBM_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of LGBC_train: ', roc_auc_score(y_train, y_prob_train))\n",
    "print('AUC of LGBC_test: ', roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89      7000\n",
      "          1       0.68      0.35      0.47      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.80      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89     16364\n",
      "          1       0.69      0.37      0.49      4636\n",
      "\n",
      "avg / total       0.81      0.83      0.80     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification for train\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bayes_train:  0.770095238095238\n",
      "Accuracy of Bayes_test:  0.771\n",
      "AUC of Bayes_train:  0.7366726759681441\n",
      "AUC of Bayes_test:  0.7342563214285713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = bnb.predict(x_train)\n",
    "y_proba_train = bnb.predict_proba(x_train)[:,1]\n",
    "\n",
    "y_pred = bnb.predict(x_test)\n",
    "y_proba = bnb.predict_proba(x_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "print('Accuracy of Bayes_train: ', accuracy_score(y_pred_train, y_train))\n",
    "print('Accuracy of Bayes_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of Bayes_train: ', roc_auc_score(y_train, y_proba_train))\n",
    "print('AUC of Bayes_test: ', roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.85      0.85      7000\n",
      "          1       0.48      0.48      0.48      2000\n",
      "\n",
      "avg / total       0.77      0.77      0.77      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85     16364\n",
      "          1       0.48      0.50      0.49      4636\n",
      "\n",
      "avg / total       0.77      0.77      0.77     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bayes_train:  0.8144285714285714\n",
      "Accuracy of Bayes_test:  0.75\n",
      "AUC of Bayes_train:  0.8292686362074707\n",
      "AUC of Bayes_test:  0.5934543214285715\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "y_pred_train = knn.predict(x_train)\n",
    "y_proba_train = knn.predict_proba(x_train)[:,1]\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "y_proba = knn.predict_proba(x_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "print('Accuracy of Bayes_train: ', accuracy_score(y_pred_train, y_train))\n",
    "print('Accuracy of Bayes_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of Bayes_train: ', roc_auc_score(y_train, y_proba_train))\n",
    "print('AUC of Bayes_test: ', roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.91      0.85      7000\n",
      "          1       0.37      0.17      0.24      2000\n",
      "\n",
      "avg / total       0.70      0.75      0.71      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.95      0.89     16364\n",
      "          1       0.66      0.34      0.44      4636\n",
      "\n",
      "avg / total       0.80      0.81      0.79     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 23, 'p': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "\n",
    "params ={'n_neighbors':sp_randint(5,30),\n",
    "         'p':sp_randint(1,5)}\n",
    "\n",
    "rand_search_knn=RandomizedSearchCV(knn,param_distributions=params,cv=3,random_state=1)\n",
    "\n",
    "rand_search_knn.fit(X,y)\n",
    "rand_search_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bayes_train:  0.7863809523809524\n",
      "Accuracy of Bayes_test:  0.7806666666666666\n",
      "AUC of Bayes_train:  0.7295936923767719\n",
      "AUC of Bayes_test:  0.6491554642857144\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(**rand_search_knn.best_params_)\n",
    "\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "y_pred_train = knn.predict(x_train)\n",
    "y_proba_train = knn.predict_proba(x_train)[:,1]\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "y_proba = knn.predict_proba(x_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "print('Accuracy of Bayes_train: ', accuracy_score(y_pred_train, y_train))\n",
    "print('Accuracy of Bayes_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of Bayes_train: ', roc_auc_score(y_train, y_proba_train))\n",
    "print('AUC of Bayes_test: ', roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.98      0.87      7000\n",
      "          1       0.54      0.09      0.16      2000\n",
      "\n",
      "avg / total       0.73      0.78      0.71      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.98      0.88     16364\n",
      "          1       0.59      0.10      0.18      4636\n",
      "\n",
      "avg / total       0.75      0.79      0.72     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "x_train_sm, y_train_sm = smote.fit_sample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion matrix - Train:  \n",
      " [[ 8626  7738]\n",
      " [ 4630 11734]]\n",
      "Overall accuracy - Train:  0.6220972867269616\n",
      "Confussion matrix - Test:  \n",
      " [[3677 3323]\n",
      " [ 560 1440]]\n",
      "Overall accuracy - Test:  0.5685555555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.53      0.65      7000\n",
      "          1       0.30      0.72      0.43      2000\n",
      "\n",
      "avg / total       0.74      0.57      0.60      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.53      0.58     16364\n",
      "          1       0.60      0.72      0.65     16364\n",
      "\n",
      "avg / total       0.63      0.62      0.62     32728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_prob = logreg.predict_proba(x_test)\n",
    "\n",
    "\n",
    "y_prob = logreg.predict_proba(x_test)[:,1]\n",
    "\n",
    "\n",
    "THRESHOLD = 0.50\n",
    "y_pred = np.where(logreg.predict_proba(x_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "#Accuracy for test \n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "#For train data\n",
    "y_prob_train = logreg.predict_proba(x_train_sm)[:,1]\n",
    "y_pred_train = np.where(logreg.predict_proba(x_train_sm)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "print('Confussion matrix - Train: ','\\n',confusion_matrix(y_train_sm,y_pred_train))\n",
    "print('Overall accuracy - Train: ',accuracy_score(y_train_sm,y_pred_train))\n",
    "print('Confussion matrix - Test: ','\\n',confusion_matrix(y_test,y_pred))\n",
    "print('Overall accuracy - Test: ',accuracy_score(y_test,y_pred))\n",
    "\n",
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train_sm,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest_train:  0.9898863358592032\n",
      "Accuracy of Random Forest_test:  0.8037777777777778\n",
      "AUC of Random Forest_train:  0.9997954780097204\n",
      "AUC of Random Forest_test:  0.7289125714285715\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.93      0.88      7000\n",
      "          1       0.60      0.36      0.45      2000\n",
      "\n",
      "avg / total       0.78      0.80      0.78      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99     16364\n",
      "          1       1.00      0.98      0.99     16364\n",
      "\n",
      "avg / total       0.99      0.99      0.99     32728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10,random_state=1)\n",
    "\n",
    "rfc.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "y_pred_train = rfc.predict(x_train_sm)\n",
    "y_prob_train = rfc.predict_proba(x_train_sm)[:,1]\n",
    "\n",
    "y_pred = rfc.predict(x_test)\n",
    "y_prob = rfc.predict_proba(x_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "print('Accuracy of Random Forest_train: ', accuracy_score(y_pred_train, y_train_sm))\n",
    "print('Accuracy of Random Forest_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of Random Forest_train: ', roc_auc_score(y_train_sm, y_prob_train))\n",
    "print('AUC of Random Forest_test: ', roc_auc_score(y_test, y_prob))\n",
    "\n",
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train_sm,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest_train:  0.7522305059887558\n",
      "Accuracy of RandomForest_test:  0.7768888888888889\n",
      "AUC of RandomForest_train:  0.8280683911348046\n",
      "AUC of RandomForest_test:  0.7255195\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.86      7000\n",
      "          1       0.50      0.51      0.50      2000\n",
      "\n",
      "avg / total       0.78      0.78      0.78      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.85      0.77     16364\n",
      "          1       0.81      0.65      0.73     16364\n",
      "\n",
      "avg / total       0.76      0.75      0.75     32728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=1)\n",
    "\n",
    "params = {'n_estimators': sp_randint(5,30),\n",
    "          'criterion' : ['gini','entropy'],\n",
    "          'max_depth' : sp_randint(2,10),\n",
    "          'min_samples_split' : sp_randint(2,20),\n",
    "          'min_samples_leaf' : sp_randint(1,20),\n",
    "          'max_features' : sp_randint(2,18)}\n",
    "\n",
    "rand_search_rfc = RandomizedSearchCV(rfc, param_distributions=params, random_state=1, cv=3)\n",
    "\n",
    "rand_search_rfc.fit(X,y)\n",
    "\n",
    "rand_search_rfc.best_params_\n",
    "\n",
    "rfc = RandomForestClassifier(**rand_search_rfc.best_params_)\n",
    "\n",
    "rfc.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "y_pred_train = rfc.predict(x_train_sm)\n",
    "y_prob_train = rfc.predict_proba(x_train_sm)[:,1]\n",
    "\n",
    "y_pred = rfc.predict(x_test)\n",
    "y_prob = rfc.predict_proba(x_test)[:,1]\n",
    "\n",
    "print('Accuracy of RandomForest_train: ', accuracy_score(y_pred_train, y_train_sm))\n",
    "print('Accuracy of RandomForest_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of RandomForest_train: ', roc_auc_score(y_train_sm, y_prob_train))\n",
    "print('AUC of RandomForest_test: ', roc_auc_score(y_test, y_prob))\n",
    "\n",
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train_sm,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train Set:  0.8724945001222195\n",
      "Accuracy on Test Set:  0.8174444444444444\n",
      "AUC of Train Set:  0.9316294286795257\n",
      "AUC of Test Set:  0.7732020714285714\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89      7000\n",
      "          1       0.65      0.39      0.49      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.80      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.94      0.88     16364\n",
      "          1       0.93      0.81      0.86     16364\n",
      "\n",
      "avg / total       0.88      0.87      0.87     32728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbc.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = lgbc.predict(x_test)\n",
    "y_prob = lgbc.predict_proba(x_test)[:,1]\n",
    "\n",
    "y_pred_train = lgbc.predict(x_train_sm)\n",
    "y_prob_train = lgbc.predict_proba(x_train_sm)[:,1]\n",
    "\n",
    "print('Accuracy on Train Set: ', accuracy_score(y_train_sm, y_pred_train))\n",
    "print('Accuracy on Test Set: ', accuracy_score(y_test, y_pred))\n",
    "print('AUC of Train Set: ', roc_auc_score(y_train_sm, y_prob_train))\n",
    "print('AUC of Test Set: ', roc_auc_score(y_test, y_prob))\n",
    "\n",
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train_sm,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM with Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LGBC_train:  0.8724945001222195\n",
      "Accuracy of LGBM_test:  0.8174444444444444\n",
      "AUC of LGBC_train:  0.9316294286795257\n",
      "AUC of LGBC_test:  0.7732020714285714\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89      7000\n",
      "          1       0.65      0.39      0.49      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.80      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.94      0.88     16364\n",
      "          1       0.93      0.81      0.86     16364\n",
      "\n",
      "avg / total       0.88      0.87      0.87     32728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "lgbc = lgb.LGBMClassifier(random_state=1)\n",
    "\n",
    "params = {'n_estimators': sp_randint(5,250),\n",
    "          'max_depth' : sp_randint(2,20),\n",
    "          'min_child_samples' : sp_randint(1,20),\n",
    "          'num_leaves' : sp_randint(5,50)}\n",
    "\n",
    "rand_search_lgbc = RandomizedSearchCV(lgbc, param_distributions=params, random_state=1, cv=3)\n",
    "\n",
    "rand_search_lgbc.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "rand_search_lgbc.best_params_\n",
    "\n",
    "lgbc = lgb.LGBMClassifier(**rand_search_lgbc.best_params_, random_state=1)\n",
    "\n",
    "lgbc.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "y_pred_train = lgbc.predict(x_train_sm)\n",
    "y_prob_train = lgbc.predict_proba(x_train_sm)[:,1]\n",
    "\n",
    "y_pred = lgbc.predict(x_test)\n",
    "y_prob = lgbc.predict_proba(x_test)[:,1]\n",
    "\n",
    "print('Accuracy of LGBC_train: ', accuracy_score(y_pred_train, y_train_sm))\n",
    "print('Accuracy of LGBM_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of LGBC_train: ', roc_auc_score(y_train_sm, y_prob_train))\n",
    "print('AUC of LGBC_test: ', roc_auc_score(y_test, y_prob))\n",
    "\n",
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train_sm,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bayes_train:  0.7283365925201662\n",
      "Accuracy of Bayes_test:  0.7904444444444444\n",
      "AUC of Bayes_train:  0.7891965440231316\n",
      "AUC of Bayes_test:  0.7099918214285714\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.89      0.87      7000\n",
      "          1       0.54      0.44      0.48      2000\n",
      "\n",
      "avg / total       0.78      0.79      0.78      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.88      0.76     16364\n",
      "          1       0.83      0.57      0.68     16364\n",
      "\n",
      "avg / total       0.75      0.73      0.72     32728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred_train = bnb.predict(x_train_sm)\n",
    "y_proba_train = bnb.predict_proba(x_train_sm)[:,1]\n",
    "\n",
    "y_pred = bnb.predict(x_test)\n",
    "y_proba = bnb.predict_proba(x_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "print('Accuracy of Bayes_train: ', accuracy_score(y_pred_train, y_train_sm))\n",
    "print('Accuracy of Bayes_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of Bayes_train: ', roc_auc_score(y_train_sm, y_proba_train))\n",
    "print('AUC of Bayes_test: ', roc_auc_score(y_test, y_proba))\n",
    "\n",
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train_sm,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bayes_train:  0.8402896602297727\n",
      "Accuracy of Bayes_test:  0.5913333333333334\n",
      "AUC of Bayes_train:  0.9525702013786694\n",
      "AUC of Bayes_test:  0.5856885714285713\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.61      0.70      7000\n",
      "          1       0.28      0.52      0.36      2000\n",
      "\n",
      "avg / total       0.70      0.59      0.62      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.72      0.82     16364\n",
      "          1       0.77      0.96      0.86     16364\n",
      "\n",
      "avg / total       0.86      0.84      0.84     32728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "y_pred_train = knn.predict(x_train_sm)\n",
    "y_proba_train = knn.predict_proba(x_train_sm)[:,1]\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "y_proba = knn.predict_proba(x_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "print('Accuracy of Bayes_train: ', accuracy_score(y_pred_train, y_train_sm))\n",
    "print('Accuracy of Bayes_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of Bayes_train: ', roc_auc_score(y_train_sm, y_proba_train))\n",
    "print('AUC of Bayes_test: ', roc_auc_score(y_test, y_proba))\n",
    "\n",
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train_sm,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bayes_train:  0.7160229772671718\n",
      "Accuracy of Bayes_test:  0.5704444444444444\n",
      "AUC of Bayes_train:  0.8106014506000467\n",
      "AUC of Bayes_test:  0.6365498928571428\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.55      0.67      7000\n",
      "          1       0.29      0.64      0.40      2000\n",
      "\n",
      "avg / total       0.72      0.57      0.61      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.58      0.67     16364\n",
      "          1       0.67      0.85      0.75     16364\n",
      "\n",
      "avg / total       0.73      0.72      0.71     32728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "\n",
    "params ={'n_neighbors':sp_randint(5,30),\n",
    "         'p':sp_randint(1,5)}\n",
    "\n",
    "rand_search_knn=RandomizedSearchCV(knn,param_distributions=params,cv=3,random_state=1)\n",
    "\n",
    "rand_search_knn.fit(X,y)\n",
    "rand_search_knn.best_params_\n",
    "\n",
    "knn=KNeighborsClassifier(**rand_search_knn.best_params_)\n",
    "\n",
    "knn.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "y_pred_train = knn.predict(x_train_sm)\n",
    "y_proba_train = knn.predict_proba(x_train_sm)[:,1]\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "y_proba = knn.predict_proba(x_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "print('Accuracy of Bayes_train: ', accuracy_score(y_pred_train, y_train_sm))\n",
    "print('Accuracy of Bayes_test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('AUC of Bayes_train: ', roc_auc_score(y_train_sm, y_proba_train))\n",
    "print('AUC of Bayes_test: ', roc_auc_score(y_test, y_proba))\n",
    "\n",
    "#Classification for test\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#classification for train\n",
    "print(classification_report(y_train_sm,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8153333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.96      0.89      7000\n",
      "          1       0.68      0.32      0.43      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.79      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.89     16364\n",
      "          1       0.69      0.34      0.45      4636\n",
      "\n",
      "avg / total       0.80      0.82      0.80     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using adaboost\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(x_train,y_train)\n",
    "y_pred = ada.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "y_pred_train = ada.predict(x_train)\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8182222222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89      7000\n",
      "          1       0.67      0.35      0.46      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.80      9000\n",
      "\n",
      "[[6660  340]\n",
      " [1296  704]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.90     16364\n",
      "          1       0.70      0.38      0.50      4636\n",
      "\n",
      "avg / total       0.81      0.83      0.81     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using Gradientboost\n",
    "grad = GradientBoostingClassifier()\n",
    "grad.fit(x_train,y_train)\n",
    "y_pred = grad.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "y_pred_train = grad.predict(x_train)\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = XGBClassifier()\n",
    "parameters = {\n",
    "     \"eta\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(clf,\n",
    "                    parameters, n_jobs=4,\n",
    "                    scoring=\"neg_log_loss\",\n",
    "                    cv=3)\n",
    "\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8185555555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89      7000\n",
      "          1       0.68      0.34      0.46      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.79      9000\n",
      "\n",
      "[[6682  318]\n",
      " [1315  685]]\n"
     ]
    }
   ],
   "source": [
    "xgb = grid.best_estimator_\n",
    "xgb.fit(x_train,y_train)\n",
    "y_pred = xgb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3425"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(685)/(685+1315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.7, eta=0.05, gamma=0.3,\n",
       "       gpu_id=-1, importance_type='gain', interaction_constraints=None,\n",
       "       learning_rate=0.0500000007, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "       n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "       validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8163333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89      7000\n",
      "          1       0.65      0.37      0.47      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.80      9000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89     16364\n",
      "          1       0.66      0.39      0.49      4636\n",
      "\n",
      "avg / total       0.80      0.82      0.80     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using adaboost\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(x_train_sm,y_train_sm)\n",
    "y_pred = ada.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "y_pred_train = ada.predict(x_train)\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8188888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89      7000\n",
      "          1       0.66      0.38      0.48      2000\n",
      "\n",
      "avg / total       0.80      0.82      0.80      9000\n",
      "\n",
      "[[6614  386]\n",
      " [1244  756]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89     16364\n",
      "          1       0.67      0.40      0.50      4636\n",
      "\n",
      "avg / total       0.81      0.82      0.81     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using Gradientboost\n",
    "grad = GradientBoostingClassifier()\n",
    "grad.fit(x_train_sm,y_train_sm)\n",
    "y_pred = grad.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "y_pred_train = grad.predict(x_train)\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = grid.best_estimator_\n",
    "xgb.fit(pd.DataFrame(x_train_sm,columns=x_train.columns),y_train_sm)\n",
    "y_pred = xgb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
